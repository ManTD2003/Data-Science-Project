{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException, TimeoutException, NoSuchWindowException\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.dienmayxanh.com/tivi',\n",
    "       'https://www.dienmayxanh.com/tu-lanh',\n",
    "       'https://www.dienmayxanh.com/may-lanh',\n",
    "       'https://www.dienmayxanh.com/may-giat'\n",
    "       'https://www.dienmayxanh.com/may-rua-chen',\n",
    "       'https://www.dienmayxanh.com/may-nuoc-nong']\n",
    "# driver.get(url)\n",
    "# print(driver.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl data\n",
    "\n",
    "def crawl_data():\n",
    "    def extract_reviews(driver):\n",
    "        \"\"\"\n",
    "        take reviews from customers\n",
    "        \"\"\"\n",
    "        reviews_data = []\n",
    "        page_number = 1\n",
    "\n",
    "        while True:\n",
    "            # print(f\"Extracting reviews from page {page_number}\")\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.comment-list\"))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                # print(\"No reviews found on this page. Exiting pagination.\")\n",
    "                break\n",
    "\n",
    "            reviews = driver.find_elements(By.CSS_SELECTOR, \"ul.comment-list > li.par\")\n",
    "            for review in reviews:\n",
    "                review_data = {}\n",
    "                try:\n",
    "                    reviewer_name = review.find_element(By.CSS_SELECTOR, \"p.cmt-top-name\").text\n",
    "                    review_data['reviewer_name'] = reviewer_name\n",
    "                except:\n",
    "                    review_data['reviewer_name'] = None\n",
    "                try:\n",
    "                    review_content = review.find_element(By.CSS_SELECTOR, \"p.cmt-txt\").text\n",
    "                    review_data['review_content'] = review_content\n",
    "                except:\n",
    "                    review_data['review_content'] = None\n",
    "\n",
    "                try:\n",
    "                    stars = review.find_elements(By.CSS_SELECTOR, \"div.cmt-top-star i\")\n",
    "                    rating = len([star for star in stars if 'iconcmt-starbuy' in star.get_attribute('class')])\n",
    "                    review_data['review_rating'] = rating\n",
    "                except:\n",
    "                    review_data['review_rating'] = None\n",
    "\n",
    "                reviews_data.append(review_data)\n",
    "\n",
    "            try:\n",
    "                next_page_number = page_number + 1\n",
    "                next_button = driver.find_element(By.XPATH, f\"//div[@class='pagcomment']/a[@title='trang {next_page_number}'][text()='›']\")\n",
    "                \n",
    "                if next_button:\n",
    "                    # print(f\"chuyen toi page {next_page_number}\")\n",
    "                    driver.execute_script(f\"ratingCmtList({next_page_number});\")\n",
    "                    page_number += 1\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    # print(\"het page, dung extracting reviews.\")\n",
    "                    break\n",
    "            except NoSuchElementException:\n",
    "                # print(\"khong co nut next. Finished extracting reviews.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                # print(f\"loi dme nooo: {e}\")\n",
    "                break\n",
    "\n",
    "        return reviews_data\n",
    "\n",
    "\n",
    "    product_links = []\n",
    "    products_data = []\n",
    "\n",
    "    products = driver.find_elements(By.CSS_SELECTOR, \"ul.listproduct > li.item\")\n",
    "    for product in products:\n",
    "        link_element = product.find_element(By.TAG_NAME, \"a\")\n",
    "        href = link_element.get_attribute('href')\n",
    "        product_links.append(href)\n",
    "\n",
    "    for index, product_link in enumerate(product_links):\n",
    "        data = {}\n",
    "        try:\n",
    "            # print(f\"\\nProcessing product {index}\")\n",
    "\n",
    "            driver.get(product_link)\n",
    "\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "            )\n",
    "\n",
    "            # get product name\n",
    "            try:\n",
    "                product_name_element = driver.find_element(By.CSS_SELECTOR, \"div.product-name > h1\")\n",
    "                product_name = product_name_element.text\n",
    "                data['name'] = product_name\n",
    "            except:\n",
    "                data['name'] = None\n",
    "\n",
    "            # get product price\n",
    "            try:\n",
    "                product_price_element = driver.find_element(By.CSS_SELECTOR, \"div.bs_price > strong\")\n",
    "                product_price = product_price_element.text\n",
    "                data['price'] = product_price\n",
    "            except:\n",
    "                data['price'] = None\n",
    "\n",
    "            # get product rating\n",
    "            try:\n",
    "                product_point_element = driver.find_element(By.CSS_SELECTOR, \"div.boxrate__top div.point > p\")\n",
    "                product_point = product_point_element.text\n",
    "                data['point'] = product_point\n",
    "            except:\n",
    "                data['point'] = None\n",
    "\n",
    "            # get reviews\n",
    "            try:\n",
    "                view_all_reviews_link = driver.find_element(By.CSS_SELECTOR, \"a.btn-view-all\")\n",
    "                reviews_page_url = view_all_reviews_link.get_attribute('href')\n",
    "\n",
    "                driver.get(reviews_page_url)\n",
    "                \n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "                )\n",
    "                \n",
    "                reviews_data = extract_reviews(driver)\n",
    "                data['reviews'] = reviews_data\n",
    "                driver.back()\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "                )\n",
    "            except NoSuchElementException:\n",
    "                reviews_data = extract_reviews(driver)\n",
    "                data['reviews'] = reviews_data\n",
    "\n",
    "            products_data.append(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Exception occurred:\", e)\n",
    "            continue\n",
    "    return products_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def save_data(products_data, category):\n",
    "    for idx, product in enumerate(products_data):\n",
    "        product['id'] = idx + 1  # Start IDs from 1\n",
    "    products_df = pd.DataFrame(products_data, columns=['id', 'name', 'price', 'point'])\n",
    "    reviews_list = []\n",
    "\n",
    "    for product in products_data:\n",
    "        product_id = product['id']\n",
    "        reviews = product.get('reviews', [])\n",
    "        for review in reviews:\n",
    "            review_data = {\n",
    "                'reviewer_name': review.get('reviewer_name'),\n",
    "                'review_content': review.get('review_content'),\n",
    "                'review_point': review.get('review_rating'),\n",
    "                'product_id': product_id\n",
    "            }\n",
    "            reviews_list.append(review_data)\n",
    "\n",
    "    reviews_df = pd.DataFrame(reviews_list, columns=['reviewer_name', 'review_content', 'review_point', 'product_id'])\n",
    "    if not os.path.exists(category):\n",
    "        os.makedirs(category)\n",
    "    products_df.to_csv(os.path.join(category, \"products.csv\"), index=False, encoding=\"utf-8\")\n",
    "    reviews_df.to_csv(os.path.join(category, \"reviews.csv\"), index=False, encoding=\"utf-8\")\n",
    "    print(f\"done with {category} category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_data(products_data, 'tivi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crawl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            see_more_button = wait.until(\n",
    "                EC.element_to_be_clickable(\n",
    "                    (By.XPATH, \"//strong[@class='see-more-btn' and contains(text(), 'Xem thêm')]\")\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", see_more_button)\n",
    "            see_more_button.click()\n",
    "            # print(\"Clicked 'See More' button\")\n",
    "            time.sleep(2) \n",
    "        except (NoSuchElementException, ElementClickInterceptedException, TimeoutException):\n",
    "            # print(\"No more 'See More' button to click or button not clickable.\")\n",
    "            break\n",
    "        except NoSuchWindowException:\n",
    "            # print(\"Browser window was closed unexpectedly.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(f\"An unexpected exception occurred: {e}\")\n",
    "            break\n",
    "    cate = url.strip().split('/')[-1]\n",
    "    data = crawl_data()\n",
    "    save_data(products_data=data, category=cate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
